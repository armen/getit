#!/bin/sh
# vim: set expandtab tabstop=4 shiftwidth=4 foldmethod=marker:
#
# Getit, simplified, yet powerful download manager
#
#   Author: Armen Baghumian <armen@OpenSourceClub.org>
#   Version: 0.1
#   License: There is no license, then you are free to do WHAT EVER YOU WANT with
#            this script
#

CONFIG="${HOME}/.getitrc"
PIDS_FILE="/tmp/getit.pids"
LOG_FILES_PREFIX="/tmp/getit.log"

# default configs
DOWNLOAD_DIR="${HOME}/downloads"
QUEUE="${DOWNLOAD_DIR}/queue.txt"
COMPLETED="${DOWNLOAD_DIR}/completed.txt"
LIMIT_RATE=0
TRIES=20
WAIT_RETRY=30
CONCURRENT_DOWNLOADS=15

# read getitrc file if it is present
[ -r $CONFIG ] && . $CONFIG

# create download directory if it is not exists
if [ "x`ls ${DOWNLOAD_DIR} 2>/dev/null`" == "x" ] ; then
    mkdir -p $DOWNLOAD_DIR

    # it seems this first attempt to run so create queue file too
    if [ "x`ls ${QUEUE} 2>/dev/null`" == "x" ] ; then
        touch ${QUEUE}
    fi
fi

# cleanup function
function clean_up {

    if [ -f $PIDS_FILE ] ; then

        cat $PIDS_FILE | while read pid;
        do
            if [ $pid ] ; then
                kill $pid 2>/dev/null
            fi
        done
    fi

    # remove log files and pids file
    rm -rf $PIDS_FILE
    rm -rf $LOG_FILES_PREFIX.*
}

function start_download {

    if [ -f $QUEUE ] ; then

        cat $QUEUE | head --lines=$CONCURRENT_DOWNLOADS | while read row;
        do
            # ignore lines that have ; or # at the beginning
            row=`echo $row | sed --expression='s/^\s*[;#].*//'`

            # extract url, download_dir and limit_rate
            url=`echo $row | awk '{print $1}'`
            download_dir="${DOWNLOAD_DIR}/`echo $row | awk '{print $2}'`"
            limit_rate=`echo $row | awk '{print $3}'`
            # strip invalid characters from limit_rate
            limit_rate=`echo $limit_rate | sed --expression="s/[^0-9KG]\+//ig"`

            if [ $url ] ; then

                if [ "x`ls ${download_dir} 2>/dev/null`" == "x" ] ; then
                    mkdir -p $download_dir
                fi

                if [ "x${limit_rate}" == "x-" -o "x${limit_rate}" == "x" ] ; then
                    limit_rate=$LIMIT_RATE;
                fi

                # prevent starting wget when other process is downloading same url, this is happening when there are
                # duplicated lines in queue file
                if [ "x`ps aux | grep wget | grep --invert-match grep | awk '{ print $NF }' | grep $url`" == "x" ] ; then

                    cd $download_dir
                    extension=`echo $url | md5sum | awk '{print $1}'`
                    wget --waitretry=$WAIT_RETRY --tries=$TRIES  --progress=bar:force --continue \
                         --limit-rate=$limit_rate --output-file=$LOG_FILES_PREFIX.$extension \
                         $url 1>/dev/null &
                    pid=$!

                    # save pid somewhere so we can cleanup it later
                    echo $pid >> $PIDS_FILE
                fi
            fi

        done
    fi
}

function terminate {
    clean_up
    kill $inotify_pid
    exit
}

# Do the cleanup when one of SIGHUP, SIGINT, SIGTERM signals is received
trap terminate SIGHUP SIGINT SIGTERM

while (true);
do
    # 2 indicates timeout
    if [ "$inotify_ret" != "2" ] ; then
        clean_up
        start_download
    else
        # run cleanup-queue in the background and quickly watch queue file again
        getitctl cleanup-queue &
    fi

    # watch queue file
    inotifywait --quiet --timeout=30 --event MOVE_SELF --event MODIFY $QUEUE 1>/dev/null &
    inotify_pid=$!      # catch its pid so we can cleanup it later when a SIGNAL received
    wait $inotify_pid   # wait for it
    inotify_ret=$?      # an then catch the return value, 2 indicates timeout
done
